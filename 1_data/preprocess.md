# 大模型预训练数据构建：行业最佳实践与内部质量审计

## 第一部分：大厂实践与学术探索指南

**核心目标：**
1.  **数据优化与效果提升：** 探索构建预训练数据（质量、多样性、配比）的最佳范式以提升模型性能。
2.  **低成本最优配置搜索：** 利用 Scaling Law，在小模型/小数据量上进行消融实验（数据配比、模型结构、超参），并将结论低成本迁移至大模型。

---

### 一、 业界大厂实践系列

#### 1. Llama 系列 (Meta)
**核心策略：** 随版本迭代显著增加数据规模，强调清洗质量与混合上采样（Up-sampling）。

*   **Llama 1 (1.4T Tokens):**
    *   **配比：** CommonCrawl (67%), C4 (15%), Github (4.5%), Wikipedia (4.5%), Books (4.5%) 等。
    *   **特点：** 基础清洗，验证了万亿级 Token 的有效性。
*   **Llama 2 (2T Tokens):**
    *   **改进：** 数据量增加 40%，强化隐私清洗，对事实性数据进行上采样。
    *   **模型：** 上下文扩展至 4k，引入 GQA (Grouped Query Attention)。
*   **Llama 3 (15T+ Tokens):**
    *   **规模与配比：** 数据量激增。配比调整为：50% 常识，25% 数学/推理，17% 代码，8% 多语言。
    *   **创新点 (Annealing)：** 在训练末期利用高质量数据进行“退火”，将 LR 降为 0，用于评估数据集价值并提升最终效果。

#### 2. Qwen 系列 (Alibaba)
**核心策略：** “质量优于数量”，引入多语言、代码及合成数据，精细化清洗 pipeline。

*   **Qwen 1 (3T):** 强调 Web 数据提取、语种识别、去重（MinHash/LSH）及模型打分过滤。
*   **Qwen 2 (7T):**
    *   **关键教训：** 曾尝试放宽质量阈值扩展至 12T，但效果不如高质量的 7T，再次证明**Quality > Quantity**。
*   **Qwen 2.5 (18T):**
    *   **策略：** 利用 Qwen2-Instruct 模型作为过滤器；大量合成数学/代码数据（Qwen2-Math/Coder）；对科学技术类高价值数据上采样，对娱乐广告类低价值数据下采样。

#### 3. Deepseek 系列
**核心策略：** 深度探索 Scaling Laws，认为高质量数据能提升模型的 Scaling 系数。

*   **V1 关键结论：**
    *   **去重收益：** 数据质量越高，模型参数增加带来的收益（Model Scaling）越高，而单纯堆砌数据量（Data Scaling）的边际收益递减。
    *   **策略建议：** 当数据质量足够高时，计算预算 $C$ 应更多投入到**扩大模型参数**上。
*   **V3 (14.8T):** 采用 FIM (Fill-In-the-Middle) 策略增强代码能力，并优化多语言压缩效率。

#### 4. Phi 系列 (Microsoft)
**核心策略：** "Textbooks Are All You Need"，极度依赖高质量合成数据。

*   **数据构成 (Phi-3/4):** Web (15%), Web Rewrites (15%), **Synthetic (40%)**, Code (20%)。
*   **结论：** 经过严格筛选的少量高质量数据（+教科书级合成数据）训练的小模型（如 1.3B），在推理能力上可击败未筛选的大参数模型。

#### 5. FineWeb & FineWeb-Edu (HuggingFace)
**核心策略：** 开源透明的数据处理流程，探索去重与“教育性”筛选的最佳实践。

*   **去重洞察：** 发现 **独立快照去重 (Individual Dump Dedup)** 优于全局去重。全局去重会过度删除早期数据并保留低质“独特”垃圾文本。
*   **质量筛选：** 不盲目沿用 C4 规则，通过 Wasserstein 距离计算新阈值。
*   **FineWeb-Edu：** 使用 Llama-3-70B 标注数据训练分类器，筛选高“教育价值”内容。实验证明，合成数据（ChatGPT生成内容）在特定语境下提升了语料质量。

#### 6. 其他重要实践
*   **InternLM (商汤):** 多阶段渐进式预训练，代码数据分级处理（High/Moderate/Low）。
*   **Skywork (天工):** 针对中英文特定配比（Web页：英40%/中30%），采用两阶段预训练（Main -> Stem）。

---

### 二、 学术界关键实验

1.  **RHO-1 (Selective Language Modeling):**
    *   **观点：** 并非所有 Token 等价。应聚焦训练那些 Loss 高于参考模型的 Token（即模型尚未掌握的知识）。
    *   **方法：** 剔除 Loss 递增的“有害数据”和持续低 Loss 的“简单数据”。
2.  **LLaMA-MoE & Sheared LLaMA:**
    *   **动态采样：** 即使 C4 的 Loss 较低，增加其权重仍能提升整体效果。证明动态调整数据配比（Dynamic Batch Loading）的有效性。
3.  **DataComp-LM (Apple):**
    *   **结论：** 基于模型的质量过滤（Model-based filtering）至关重要。单纯混合高质量数据并不总能保证结果最优，需警惕数据污染。

---

## 第二部分：内部数据质量审计与改进分析

*本部分针对现有数据处理流程（General_CN/EN, Code, Math, Search等）中发现的共性与特性问题进行汇总，旨在为下一阶段的数据治理提供依据。*

### 2.1 数据质量核心问题汇总

#### 2.1.1 内容完整性与准确性 (Integrity & Accuracy)
*   **截断问题 (Truncation)：** 跨模态（Code, General_EN）普遍存在，导致上下文丢失，严重影响长文本建模能力。
*   **信息密度不足：**
    *   Code：早期数据存在大量短文本、无意义注释。
    *   Math：存在“每行字符极少”的排版问题，甚至部分题目缺失答案。
    *   General_CN：存在无意义表格、大量重复内容。
*   **逻辑错误与幻觉风险：** Math 数据中发现内容本身错误；Search 数据中包含“网页不存在”的无效索引，可能导致模型产生幻觉。

#### 2.1.2 格式规范与编码 (Formatting & Encoding)
*   **提取噪声：** 边框符号、装饰性字符严重干扰清洗。
*   **特殊字符与乱码：**
    *   General_CN 存在 Unicode 隐形字符（`\ufeff`, `\xa0`）。
    *   Math 和 Match 数据中存在明显的乱码问题。
*   **排版与分词干扰：**
    *   **空格缺失/滥用：** 英文单词粘连、中文不连贯（错误插入空格）、中英文之间缺乏空格。
    *   **分隔符缺失：** General_EN 整段文本无换行或分隔，Math 公式显示异常。

#### 2.1.3 识别与分类 (Recognition & Classification)
*   **语种混淆 (LID Errors)：** 英文内容被错误标记为简体中文（SIMP_CHINESE），这是严重的噪音源。
*   **类型误判：**
    *   Code：非代码文本（Meta信息、Issue讨论）被误标为 Code。
    *   General_EN：代码片段被混入通用文本。
*   **OCR 伪影：** PDF 转录数据（General_CN, Math）中存在大量 OCR 识别错误，导致语义崩坏。

#### 2.1.4 数据源噪音 (Source Quality)
*   **低价值内容：**
    *   Code：Github Issue/Commit 中的闲聊。
    *   General_CN：混入软文广告。
    *   Search-utilizable：中英日语言混杂，且中文部分质量堪忧。

#### 2.1.5 质量评分系统 (Scoring System)
*   **评分失准：** 模型打分存在两极化或反直觉现象（低质高分、高质低分、大量0分），表明质量评估模型（Reward Model/Classifier）泛化能力不足。

---

### 2.2 近期迭代发现的新增/持续性问题

在最新的数据审查（二期、四期）中，以下问题尤为突出：

*   **Math 领域（重灾区）：**
    *   **格式崩坏：** 行内重复（>3次）、乱码、OCR错误持续存在。
    *   **多模态残留：** 文本中内嵌图片标记，未转录为有效文本。
    *   **低质行：** 存在大量无意义序号或单字符行。
*   **Search 领域：** 历史数据（History）存在有效性问题，抓取链路需优化。
*   **通用文本：** PDF 解析带来的“中文不连贯”与“空格滥用”仍未根除；“截断”与“边框”问题依旧是 General_EN 的痛点。

---

### 2.3 思考与优化战略

#### 3.1 现状评估
*   **优势：** 已建立覆盖五大领域（General CN/EN, Math, Code, Search）的完整处理链路（格式化->去重->打分）；依托 AFS 存储与大数据算力，具备处理 TB 级数据的 Scaling 能力；MinHash+LSH 去重等基础设施已就位。
*   **挑战：** 自动化清洗的“颗粒度”不足，特定领域的“清洗死角”（如 Math 公式、OCR 纠错）依然存在。

#### 3.2 战略改进路线图 (Roadmap)

1.  **源头治理与解析优化 (Source & Parsing)：**
    *   **PDF/OCR 专项优化：** 针对 PDF 转录数据引入更强的 OCR 后处理模型，重点解决中文不连贯和乱码问题。
    *   **提取规则升级：** 修正文本提取脚本，解决“边框”噪音和“截断”问题，确保文档完整性。

2.  **精细化清洗与规范化 (Refined Cleaning)：**
    *   **空格与标点标准化：** 统一处理 Unicode 空格（`\xa0` 转空格），强制执行中英文间距规范，修复单词粘连。
    *   **低质行过滤：** 实施严格的“短行/无意义行”过滤策略（尤其针对 Math 和 Code）。

3.  **分类与质量模型迭代 (Classifier Iteration)：**
    *   **LID 模型升级：** 重新训练或微调语种识别模型，重点解决 EN->CN 的误判。
    *   **Reward Model 校准：** 对打分模型进行人工对齐（Human Alignment），纠正“低质高分”现象，引入针对 Code/Math 的特定维度打分。

4.  **自动化与流程标准化 (Automation & Ops)：**
    *   **自动化质检：** 开发基于规则的自动化检测工具（检测重复行、截断符、乱码率），在进入训练前拦截坏数据。
    *   **合成数据增强：** 参考业界（Phi/Qwen）经验，针对 Math 和 Code 领域，考虑引入合成数据以修补原始数据中的错误和缺失。